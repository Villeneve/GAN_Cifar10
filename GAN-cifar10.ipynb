{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 18:22:10.250309: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742678530.266515    6012 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742678530.271156    6012 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-22 18:22:10.287255: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.api as keras\n",
    "from keras.api.layers import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742678534.132958    6012 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10153 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.94509804..0.9764706].\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAC2VJREFUeJzt3D1snWcZx+HnOE5inMQxqRuKVFRaIugHUwdYilSpEiCEUIWQWBALAwMrW4cuCLHAwA4STIiPIgFTBz6GEjpQiagqNAqRU0UhJI7r2CeO45zkZQD+oKoqz011Yju5rvnW3TfHzvnlHXqPhmEYGgC01mZ2+gEA2D1EAYAQBQBCFAAIUQAgRAGAEAUAQhQAiNnewTfWt0uLZ2a2CrOl1W1+pvux22S79tyr6+Pu2fH6amn3ytkz3bPLp/5Q2v2LH363NP/i6ze6Z2+WNre2rzB7q7h7mirP3VrhL09rrf/Thunp+X+VvSkAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIA0X2+ZXLhtdLi1UvL3bPVG0LrK/3zy2fOlnafOX26f/fpU6XdZ/90uXu29om0tl6cr94zqthN94wqqs+9V/+ce9fB4vykMOun+W/eFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBGwzAMPYOfPj4qLV7uv+jQxqXNra0UZm8UdwN3ytHS9P77HyzNf/5LX+6e/en3v1HafevqRml+t+j5uvemAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAET37aPRqHb7CGAnfeqrz3XPHp6cL+3+2fd+UH2cXcHtIwBKRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYCY3ekHgOk5UpzfmMpTsDPWLr7RPTveujTFJ9lbvCkAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAMRqGYegaHI2m/Sz8l+qn3fVDvAvcf7D/ntHlG24Z3dP2P9Q/e/Pc9J5jF+n5uvemAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCADG70w/A21sqzld/kFuF2bXi7mme3Hj0yY92z14+eXKKT8Kud3N9p59g6u6fwk5vCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEC4fXQHHSrMHpjaU/zTfGF2Utxd+aWaOfhEafdke672MNy7Rgv9s8ObU3uMg8X5E6P+2fnKX+RO3hQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgnLm4g64VZreKu6vHH7YLszeLu+878oHu2SubS6XdJ//4m+LTcM86VvjdunKutPrIe+7rnt24fqW0e2von53ClQtvCgD8hygAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAuH20S90qzlfuKrXW2v7C7L7i7vkHHu2evbK2UFt+uTL8cG13u12cr93L4a0OFudP1MavVL7ePlRavXH9r7VnKZgUZueKf316eFMAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAwu2ju8Rj763Nf/JzX+menV16vLR7beaD3bNvrB4o7X7ttae7Zy9urpd231peLs23q6dq8yVrhdnqv+0q13UuFndvFmZrP/vWtorz2/2jh4rPUj02VrBwqH92UvlRdvKmAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCAOHMxR10sDD79DPPlHZ/7Nmvl+YPHz/RPbu6UjgX0FobFy4jzB+r/QqeePJ4/3OcPV3avX5sqTQ/rPR/huULDbP9ZxdGB2qf4TAe9w9fKJ65uF6Zr/1etbZSG3/ogf7Zcz+p7Z6iufn+2e3qR9jBmwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQo2EYhq7B0Wjaz7LnVG4ZtdbaU198vnv2+ONfKO1+9dKkNH/+wqXu2e1x8cDKTP/dnoXi9a3xpP+I0MZW7bn33649y+xs/2d+bGGutPvY4mL37APztd3Hj/Uf15mZr/1eXRr3z//+lTOl3RvLr5bm2+svVIZru6foscIXS/V43amt//11700BgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAovp/Se851eMcXTc//uWRT3yttHt1/qnu2V+/+Epp93BhszTfxoX54pWLdqD/1+raXPG2xOH+ExqV52ittZtztT/oza3+kw5rM4dLuzcna92z54s/n8X5xe7ZpaX+2dZam5nrP7kxHo9Lu/fN1/4Ne2sXna6o2Lyxs/99bwoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAjIZh6Dr3MxpVrwjtVU/0jx75TG114S5M2+6/q9Naa+3qVm2+Feb3LRR3Fyws1uYXC59h9bLXTPUzLPyMbhduNrXWWuGuUiuevWrjwu6Z4odYOfE0X7t91M59pzbfdviI0B1wsDi/1fF1700BgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAwpmLd6X6mSwVZh8s7j5enF8szFbPXFROdFT/XVI5RVG9c7FdnK/clyieuWi3p7i78plXT39UnvtCcffLxXnequfr3psCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEG4fMQWV35XDxd2V+cXi7srNptbqz15RucNUfY7KTajqZzJXmP1dcTfvlttHAJSIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAITbR2/x/sLs34q77yvMrhZ3d/0QYeoOFWavTe0peHtuHwFQIgoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgDEnjxzcbQwe3VqTwGwtzhzAUCJKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEDM7vQDtNbaR4rzj7+vf/bnfy8uh05PFGZ//Mva7tPf6p/95ku13c9+vH92crq2+/k3a/PsPt4UAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAILrPXBwpLv5wYfbRh2u7L2zW5mEaVgqzvy2crWitteXC6Yq/1Fa3X73cP7te3M3e500BgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQAiNEwDEPP4GePjUqLZ+b6Z+cOl1a38xf7Z09u1HYD3K16vu69KQAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEDM9g4eWKgt3pz0z66tFndv9s8era1uV4vzAHcTbwoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAdN8+ardri9fW+mfXr9V2F04fFf6AAHhTACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgOi+AnFhpbZ49Xr/7KS2uo0Ls1eKuwHuZd4UAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgOi+fVS5ZdRa7T7Rdm21e0YAU+JNAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAIju20eT4uKtwuybxd0ATIc3BQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAIjuMxdVm9NaDHvQt5+rzb/wQv/sS3+u7YZ34k0BgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQAiO7bR2vFxTeK83A3e+VHtflHDvTPvlRbDe/ImwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgDEaBiGoWdwfjQqLb7+fz0OANPS83XvTQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFACI2d7B28XF+wqzt4q7AZgObwoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQo2EYhp1+CAB2B28KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAxD8ArMCmM05wysoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train,y_train),(_,_) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train = x_train[y_train[:,0] == 1]\n",
    "x_train = (tf.cast(x_train,tf.float32)-127.5) / 127.5\n",
    "\n",
    "n = np.random.randint(0,x_train.shape[0])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "data = tf.data.Dataset.from_tensor_slices((x_train)).shuffle(x_train.shape[0]).batch(batch_size,drop_remainder=True)\n",
    "\n",
    "complete_hist = {\n",
    "    'loss_dis': [],\n",
    "    'loss_gen': [],\n",
    "}\n",
    "\n",
    "plt.imshow(x_train[n])\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Discriminator\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Discriminator\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,336</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mini_batch (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">miniBatch</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">356</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">128,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">357</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │        \u001b[38;5;34m14,336\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m1,179,904\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_5 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m295,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_6 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m73,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_7 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mini_batch (\u001b[38;5;33mminiBatch\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m356\u001b[0m)            │       \u001b[38;5;34m128,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m357\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,691,429</span> (6.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,691,429\u001b[0m (6.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,691,429</span> (6.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,691,429\u001b[0m (6.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">132,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,712</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">62,211</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │       \u001b[38;5;34m132,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m147,712\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │        \u001b[38;5;34m62,211\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,529,347</span> (5.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,529,347\u001b[0m (5.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,525,763</span> (5.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,525,763\u001b[0m (5.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,584</span> (14.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,584\u001b[0m (14.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class miniBatch(keras.layers.Layer):\n",
    "    def __init__(self,num_kernels,kernel_dim,batch_size):\n",
    "        super(miniBatch,self).__init__()\n",
    "        self.num_kernels = num_kernels\n",
    "        self.kernel_dim = kernel_dim\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        print(input_shape)\n",
    "        self.T = self.add_weight(\n",
    "            shape=(input_shape[-1],self.num_kernels*self.kernel_dim), # Teoricamente 128x500\n",
    "            initializer='random_normal',\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        M = tf.matmul(x,self.T) # teoricamente 128x128 \\times 128x500 = 128x500\n",
    "        M = tf.reshape(M,(-1,self.num_kernels,self.kernel_dim)) # teoricamente 128x100x5\n",
    "        M_T = tf.expand_dims(M,1) # teoricamente 128x1x100x5\n",
    "        M = tf.expand_dims(M,0) # teoricamente 1x128x100x5\n",
    "        diff = tf.abs(M-M_T)\n",
    "        exp_diff = tf.exp(-tf.reduce_mean(diff,-1))\n",
    "        miniBatch_features = tf.reduce_sum(exp_diff,1)\n",
    "        output = tf.concat([x,miniBatch_features],-1)\n",
    "        return output\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # Define a forma de saída explicitamente\n",
    "        return (input_shape[0], input_shape[1] + self.num_kernels)\n",
    "\n",
    "class PixelShuffle(keras.layers.Layer):\n",
    "    def __init__(self, upscale_factor):\n",
    "        super(PixelShuffle, self).__init__()\n",
    "        self.upscale_factor = upscale_factor\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size = input_shape[0]\n",
    "        h = input_shape[1]\n",
    "        w = input_shape[2]\n",
    "        c = input_shape[3]\n",
    "        out_c = c // (self.upscale_factor ** 2)\n",
    "        x = tf.reshape(inputs, (batch_size, h, w, self.upscale_factor, self.upscale_factor, out_c))\n",
    "        x = tf.transpose(x, [0, 1, 2, 4, 3, 5])\n",
    "        x = tf.reshape(x, (batch_size, h * self.upscale_factor, w * self.upscale_factor, out_c))\n",
    "        return x\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        h, w, c = input_shape[1], input_shape[2], input_shape[3]\n",
    "        out_c = c // (self.upscale_factor ** 2)\n",
    "        return (input_shape[0], h * self.upscale_factor, w * self.upscale_factor, out_c)\n",
    "    \n",
    "def residual_Gblock(x):\n",
    "\n",
    "    skip = x\n",
    "    x = Conv2D(x.shape[-1],3,1,'same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(.2)(x)\n",
    "    x = Conv2D(x.shape[-1],3,1,'same')(x)\n",
    "    x = Add()([x,skip])\n",
    "\n",
    "    return x\n",
    "\n",
    "def residual_Dblock(x):\n",
    "\n",
    "    skip = x\n",
    "    x = Conv2D(x.shape[-1],3,1,'same')(x)\n",
    "    x = LeakyReLU(.2)(x)\n",
    "    x = Conv2D(x.shape[-1],3,1,'same')(x)\n",
    "    x = Add()([x,skip])\n",
    "    x = LeakyReLU(.2)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_discriminator():\n",
    "    \n",
    "    input = Input((32,32,3))\n",
    "    x=input\n",
    "    k = 1\n",
    "    for _ in range(4):\n",
    "        x = Conv2D(512//k,3,2,'same')(x)\n",
    "        x = LeakyReLU(.2)(x)\n",
    "        k = k*2\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = miniBatch(100,5,128)(x)\n",
    "    x = Dense(1)(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    \n",
    "\n",
    "    return keras.Model(input,x,name='Discriminator')\n",
    "\n",
    "def create_generator():\n",
    "\n",
    "    input = Input((128,))\n",
    "\n",
    "    x = Dense(4*4*64)(input)\n",
    "    x = LeakyReLU(.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Reshape((4,4,64))(x)\n",
    "\n",
    "    for _ in range(3):\n",
    "        x = Conv2DTranspose(256,3,2,'same')(x)\n",
    "        x = LeakyReLU(.2)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(3,9,1,'same')(x)\n",
    "    x = Activation('tanh')(x)\n",
    "\n",
    "    return keras.Model(input,x)\n",
    "\n",
    "gen = create_generator()\n",
    "dis = create_discriminator()\n",
    "dis.summary()\n",
    "gen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce = keras.losses.BinaryCrossentropy()\n",
    "MSE = keras.losses.MeanSquaredError()\n",
    "\n",
    "LR = 1e-4\n",
    "\n",
    "gen_opt = keras.optimizers.Adam(LR,.5)\n",
    "dis_opt = keras.optimizers.Adam(LR/2,.5)\n",
    "n = 5\n",
    "noise_out = tf.random.normal((n**2,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L = 0, layer = <InputLayer name=input_layer_1, built=True>\n",
      "L = 1, layer = <Conv2D name=conv2d_1, built=True>\n",
      "L = 2, layer = <LeakyReLU name=leaky_re_lu_4, built=True>\n",
      "L = 3, layer = <Conv2D name=conv2d_2, built=True>\n",
      "L = 4, layer = <LeakyReLU name=leaky_re_lu_5, built=True>\n",
      "L = 5, layer = <Conv2D name=conv2d_3, built=True>\n",
      "L = 6, layer = <LeakyReLU name=leaky_re_lu_6, built=True>\n",
      "L = 7, layer = <Conv2D name=conv2d_4, built=True>\n",
      "L = 8, layer = <LeakyReLU name=leaky_re_lu_7, built=True>\n",
      "L = 9, layer = <Flatten name=flatten, built=True>\n",
      "L = 10, layer = <miniBatch name=mini_batch, built=True>\n",
      "L = 11, layer = <Dense name=dense_1, built=True>\n",
      "L = 12, layer = <Activation name=activation_1, built=True>\n"
     ]
    }
   ],
   "source": [
    "for i,layer in enumerate(dis.layers):\n",
    "    print(f'L = {i}, layer = {layer}')\n",
    "\n",
    "#n = np.random.uniform(0,1,(1,32,32,3))\n",
    "\n",
    "maps = keras.Model(dis.input, dis.layers[7].output)\n",
    "# map = maps(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_weights(model,clip_value=0.1):\n",
    "    \n",
    "    for layer in model.trainable_variables:\n",
    "        layer.assign(tf.clip_by_value(layer, -clip_value, clip_value))\n",
    "\n",
    "# def gradient_penalty(discriminator, real_samples, fake_samples):\n",
    "#     alpha = tf.random.uniform((real_samples.shape[0],), 0, 1)\n",
    "#     interpolated_samples = alpha[0] * real_samples + (1 - alpha[0]) * fake_samples\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         tape.watch(interpolated_samples)\n",
    "#         predictions = discriminator(interpolated_samples)\n",
    "#     gradients = tape.gradient(predictions, interpolated_samples)\n",
    "#     gradients_norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=1))\n",
    "#     penalty = tf.reduce_mean((gradients_norm - 1) ** 2)\n",
    "#     return penalty\n",
    "\n",
    "# def wasser_dist(y_true,y_pred):\n",
    "#     return tf.reduce_mean(y_true * y_pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step():\n",
    "    gen_loss,dis_loss = 0.,0.\n",
    "    gen_loss_iter,dis_loss_iter = 0.,0.\n",
    "    for batch in data:\n",
    "        \n",
    "        noise = tf.random.normal((batch_size,128))\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape:\n",
    "            fake_imgs = gen(noise,training=True)\n",
    "            true_labels = dis(batch,training=True)\n",
    "            fake_labels = dis(fake_imgs,training=True)\n",
    "            true_map = maps(batch,training=True)\n",
    "            fake_map = maps(fake_imgs, training=True)\n",
    "\n",
    "            \n",
    "            gen_loss_iter = bce(tf.ones_like(fake_labels),fake_labels) + MSE(true_map,fake_map)#- (1/2)*tf.reduce_mean(tf.math.reduce_std(fake_imgs,axis=0))\n",
    "            dis_loss_iter = bce(tf.ones_like(true_labels),true_labels) + bce(tf.zeros_like(fake_labels),fake_labels)\n",
    "            # dis_loss_iter = tf.reduce_mean(fake_labels) - tf.reduce_mean(true_labels)\n",
    "            # gen_loss_iter = -tf.reduce_mean(fake_labels) + MSE(true_map,fake_map)\n",
    "        \n",
    "        gen_gras = gen_tape.gradient(gen_loss_iter,gen.trainable_variables)\n",
    "        gen_opt.apply_gradients(zip(gen_gras,gen.trainable_variables))\n",
    "\n",
    "        dis_grads = dis_tape.gradient(dis_loss_iter,dis.trainable_variables)\n",
    "        dis_opt.apply_gradients(zip(dis_grads,dis.trainable_variables))\n",
    "\n",
    "        gen_loss += gen_loss_iter\n",
    "        dis_loss += dis_loss_iter\n",
    "        gen_loss_iter,dis_loss_iter = 0.,0.\n",
    "\n",
    "    return gen_loss/tf.cast(len(data),tf.float32),dis_loss/tf.cast(len(data),tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742678539.847036    6104 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep = 0 | Loss_gen = 1.6882; Loss_dis = 0.6451\n",
      "Ep = 10 | Loss_gen = 4.7847; Loss_dis = 0.1495\n",
      "Ep = 20 | Loss_gen = 1.8987; Loss_dis = 0.7394\n",
      "Ep = 30 | Loss_gen = 2.3323; Loss_dis = 0.5412\n",
      "Ep = 40 | Loss_gen = 2.9436; Loss_dis = 0.4734\n",
      "Ep = 50 | Loss_gen = 2.3578; Loss_dis = 0.4634\n",
      "Ep = 60 | Loss_gen = 2.3968; Loss_dis = 0.4944\n",
      "Ep = 70 | Loss_gen = 2.4075; Loss_dis = 0.5632\n",
      "Ep = 80 | Loss_gen = 2.1556; Loss_dis = 0.5480\n",
      "Ep = 90 | Loss_gen = 2.3701; Loss_dis = 0.4905\n",
      "Ep = 100 | Loss_gen = 2.3409; Loss_dis = 0.4797\n",
      "Ep = 110 | Loss_gen = 2.2721; Loss_dis = 0.4758\n",
      "Ep = 120 | Loss_gen = 2.3659; Loss_dis = 0.4785\n",
      "Ep = 130 | Loss_gen = 2.3277; Loss_dis = 0.4702\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5000\n",
    "EPOCH_SAMPLE = 10\n",
    "\n",
    "loss_dis, loss_gen = 0.,0.\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "\n",
    "    # Histórico de Loss\n",
    "    \n",
    "    loss_gen, loss_dis = train_step()\n",
    "    #loss_gen, loss_dis = loss_gen.numpy(), loss_dis.numpy()\n",
    "    clip_weights(dis,0.1)\n",
    "    complete_hist['loss_gen'].append(loss_gen)\n",
    "    complete_hist['loss_dis'].append(loss_dis)\n",
    "    \n",
    "    # Iteração das épocas\n",
    "    if i % EPOCH_SAMPLE == 0:\n",
    "        # Print Loss\n",
    "        print(f'Ep = {i} | Loss_gen = {loss_gen:.4f}; Loss_dis = {loss_dis:.4f}')\n",
    "        # Salvar uma amostra das imagens\n",
    "        img_fake = gen(noise_out)\n",
    "        fig, ax = plt.subplots(n,n,figsize=(1,1))\n",
    "        ax = ax.ravel()\n",
    "        for ii in range(n**2):\n",
    "            ax[ii].imshow(np.uint8(img_fake[ii]*127.5+127.5))\n",
    "            ax[ii].set_axis_off()\n",
    "        plt.savefig(f'imgs/fig{if}.png',dpi=1000)\n",
    "        plt.close()\n",
    "\n",
    "    plt.semilogy(np.array(complete_hist['loss_gen']),label=f'GEN = {loss_gen:.4f}')\n",
    "    plt.semilogy(np.array(complete_hist['loss_dis']),label=f'DIS = {loss_dis:.4f}')\n",
    "    plt.legend()\n",
    "    plt.grid(True,'minor')\n",
    "    plt.savefig('loss.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "print('==================== COMPLETE ====================')\n",
    "\n",
    "# plt.Figure()\n",
    "# plt.plot(loss_list[:,0],label='Discriminator')\n",
    "# plt.plot(loss_list[:,1],label='GAN')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.save('generator_cars.keras')\n",
    "dis.save('discriminator_cars.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "\n",
    "noise_out = tf.random.normal((1000,1024))\n",
    "\n",
    "img_fake = gen(noise_out)\n",
    "out_true = dis(x_train[0:1000])\n",
    "out_fake = dis(gen(tf.random.uniform((1000,1024))))\n",
    "\n",
    "print(f'Média True = {tf.reduce_mean(out_true):.4f} \\nMédia False = {tf.reduce_mean(out_fake):.4f}')\n",
    "\n",
    "plt.Figure()\n",
    "plt.semilogy(np.array(complete_hist['loss_gen']),label='GEN')\n",
    "plt.semilogy(np.array(complete_hist['loss_dis']),label='DIS')\n",
    "plt.legend()\n",
    "plt.grid(True,'minor')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(n,n,figsize=(10,10))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i in range(n**2):\n",
    "    ax[i].imshow(img_fake[i])\n",
    "    ax[i].set_axis_off()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
