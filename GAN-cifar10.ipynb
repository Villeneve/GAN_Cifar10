{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 11:38:22.361934: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742827102.377425  291023 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742827102.381951  291023 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-24 11:38:22.397680: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.api as keras\n",
    "from keras.api.layers import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742827106.319904  291023 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10152 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.0..1.0].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train,y_train),(_,_) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train = x_train[y_train[:,0] == 1]\n",
    "x_train = (tf.cast(x_train,tf.float32)-127.5) / 127.5\n",
    "\n",
    "n = np.random.randint(0,x_train.shape[0])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "data = tf.data.Dataset.from_tensor_slices((x_train)).shuffle(x_train.shape[0]).batch(batch_size,drop_remainder=True)\n",
    "\n",
    "complete_hist = {\n",
    "    'loss_dis': [],\n",
    "    'loss_gen': [],\n",
    "}\n",
    "\n",
    "plt.imshow(x_train[n])\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Discriminator\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Discriminator\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,336</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mini_batch (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">miniBatch</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">356</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">128,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">356</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">357</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │        \u001b[38;5;34m14,336\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m1,179,904\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m295,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_5 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m73,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_6 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mini_batch (\u001b[38;5;33mminiBatch\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m356\u001b[0m)            │       \u001b[38;5;34m128,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m356\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m357\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,691,429</span> (6.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,691,429\u001b[0m (6.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,691,429</span> (6.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,691,429\u001b[0m (6.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">131072</span>)         │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,908,288</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">131072</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">131072</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ self_attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,245,440</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,718,848</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,915</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m131072\u001b[0m)         │    \u001b[38;5;34m16,908,288\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m131072\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m131072\u001b[0m)         │       \u001b[38;5;34m524,288\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ self_attention (\u001b[38;5;33mSelfAttention\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │     \u001b[38;5;34m5,245,440\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m4,718,848\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d (\u001b[38;5;33mUpSampling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_1 (\u001b[38;5;33mUpSampling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │         \u001b[38;5;34m6,915\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,995,907</span> (106.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m27,995,907\u001b[0m (106.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,732,739</span> (105.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m27,732,739\u001b[0m (105.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> (1.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m263,168\u001b[0m (1.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class miniBatch(keras.layers.Layer):\n",
    "    def __init__(self,num_kernels,kernel_dim,batch_size):\n",
    "        super(miniBatch,self).__init__()\n",
    "        self.num_kernels = num_kernels\n",
    "        self.kernel_dim = kernel_dim\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        print(input_shape)\n",
    "        self.T = self.add_weight(\n",
    "            shape=(input_shape[-1],self.num_kernels*self.kernel_dim), # Teoricamente 128x500\n",
    "            initializer='random_normal',\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        M = tf.matmul(x,self.T) # teoricamente 128x128 \\times 128x500 = 128x500\n",
    "        M = tf.reshape(M,(-1,self.num_kernels,self.kernel_dim)) # teoricamente 128x100x5\n",
    "        M_T = tf.expand_dims(M,1) # teoricamente 128x1x100x5\n",
    "        M = tf.expand_dims(M,0) # teoricamente 1x128x100x5\n",
    "        diff = tf.abs(M-M_T)\n",
    "        exp_diff = tf.exp(-tf.reduce_mean(diff,-1))\n",
    "        miniBatch_features = tf.reduce_sum(exp_diff,1)\n",
    "        output = tf.concat([x,miniBatch_features],-1)\n",
    "        return output\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # Define a forma de saída explicitamente\n",
    "        return (input_shape[0], input_shape[1] + self.num_kernels)\n",
    "\n",
    "class PixelShuffle(keras.layers.Layer):\n",
    "    def __init__(self, upscale_factor):\n",
    "        super(PixelShuffle, self).__init__()\n",
    "        self.upscale_factor = upscale_factor\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size = input_shape[0]\n",
    "        h = input_shape[1]\n",
    "        w = input_shape[2]\n",
    "        c = input_shape[3]\n",
    "        out_c = c // (self.upscale_factor ** 2)\n",
    "        x = tf.reshape(inputs, (batch_size, h, w, self.upscale_factor, self.upscale_factor, out_c))\n",
    "        x = tf.transpose(x, [0, 1, 2, 4, 3, 5])\n",
    "        x = tf.reshape(x, (batch_size, h * self.upscale_factor, w * self.upscale_factor, out_c))\n",
    "        return x\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        h, w, c = input_shape[1], input_shape[2], input_shape[3]\n",
    "        out_c = c // (self.upscale_factor ** 2)\n",
    "        return (input_shape[0], h * self.upscale_factor, w * self.upscale_factor, out_c)\n",
    "    \n",
    "\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, filters):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.filters = filters\n",
    "        self.query_conv = Conv2D(filters // 8, kernel_size=1)\n",
    "        self.key_conv = Conv2D(filters // 8, kernel_size=1)\n",
    "        self.value_conv = Conv2D(filters, kernel_size=1)\n",
    "        self.softmax = Softmax(axis=-1)\n",
    "    \n",
    "    def call(self, x):\n",
    "        batch, height, width, channels = tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2], tf.shape(x)[3]\n",
    "\n",
    "        Q = tf.reshape(self.query_conv(x), (batch, height * width, -1))  # [B, HW, C/8]\n",
    "        K = tf.reshape(self.key_conv(x), (batch, -1, height * width))    # [B, C/8, HW]\n",
    "        V = tf.reshape(self.value_conv(x), (batch, height * width, -1))  # [B, HW, C]\n",
    "\n",
    "        attention_map = self.softmax(tf.matmul(Q, K))  # [B, HW, HW]\n",
    "\n",
    "        attention_output = tf.matmul(attention_map, V)  # [B, HW, C]\n",
    "        attention_output = tf.reshape(attention_output, (batch, height, width, channels))\n",
    "\n",
    "        return attention_output + x\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def residual_Gblock(x):\n",
    "\n",
    "    skip = x\n",
    "    x = Conv2D(x.shape[-1],3,1,'same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(.2)(x)\n",
    "    x = Conv2D(x.shape[-1],3,1,'same')(x)\n",
    "    x = Add()([x,skip])\n",
    "\n",
    "    return x\n",
    "\n",
    "def residual_Dblock(x):\n",
    "\n",
    "    skip = x\n",
    "    x = Conv2D(x.shape[-1],3,1,'same')(x)\n",
    "    x = LeakyReLU(.2)(x)\n",
    "    x = Conv2D(x.shape[-1],3,1,'same')(x)\n",
    "    x = Add()([x,skip])\n",
    "    x = LeakyReLU(.2)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_discriminator():\n",
    "    \n",
    "    input = Input((32,32,3))\n",
    "    x = input\n",
    "    k = 1\n",
    "    for _ in range(4):\n",
    "        x = Conv2D(512//k,3,2,'same')(x)\n",
    "        x = LeakyReLU(.2)(x)\n",
    "        k = k*2\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = miniBatch(100,5,128)(x)\n",
    "    x = Dropout(.3)(x)\n",
    "    x = Dense(1)(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    \n",
    "\n",
    "    return keras.Model(input,x,name='Discriminator')\n",
    "\n",
    "def create_generator():\n",
    "\n",
    "    input = Input((128,))\n",
    "\n",
    "    x = Dense(8*8*2048)(input)\n",
    "    x = LeakyReLU(.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Reshape((8,8,2048))(x)\n",
    "    x = SelfAttention(x.shape[-1])(x)\n",
    "\n",
    "    for _ in range(2):\n",
    "        x = Conv2DTranspose(256,3,1,'same')(x)\n",
    "        x = UpSampling2D()(x)\n",
    "        x = LeakyReLU(.2)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(3,3,1,'same')(x)\n",
    "    x = Activation('tanh')(x)\n",
    "\n",
    "    return keras.Model(input,x)\n",
    "\n",
    "gen = create_generator()\n",
    "dis = create_discriminator()\n",
    "dis.summary()\n",
    "gen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce = keras.losses.BinaryCrossentropy()\n",
    "MSE = keras.losses.MeanSquaredError()\n",
    "\n",
    "LR = 1e-4\n",
    "\n",
    "gen_opt = keras.optimizers.Adam(LR,.5)\n",
    "dis_opt = keras.optimizers.Adam(LR/2,.5)\n",
    "n = 5\n",
    "noise_out = tf.random.normal((n**2,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L = 0, layer = <InputLayer name=input_layer_1, built=True>\n",
      "L = 1, layer = <Conv2D name=conv2d_4, built=True>\n",
      "L = 2, layer = <LeakyReLU name=leaky_re_lu_3, built=True>\n",
      "L = 3, layer = <Conv2D name=conv2d_5, built=True>\n",
      "L = 4, layer = <LeakyReLU name=leaky_re_lu_4, built=True>\n",
      "L = 5, layer = <Conv2D name=conv2d_6, built=True>\n",
      "L = 6, layer = <LeakyReLU name=leaky_re_lu_5, built=True>\n",
      "L = 7, layer = <Conv2D name=conv2d_7, built=True>\n",
      "L = 8, layer = <LeakyReLU name=leaky_re_lu_6, built=True>\n",
      "L = 9, layer = <Flatten name=flatten, built=True>\n",
      "L = 10, layer = <miniBatch name=mini_batch, built=True>\n",
      "L = 11, layer = <Dropout name=dropout, built=True>\n",
      "L = 12, layer = <Dense name=dense_1, built=True>\n",
      "L = 13, layer = <Activation name=activation_1, built=True>\n"
     ]
    }
   ],
   "source": [
    "for i,layer in enumerate(dis.layers):\n",
    "    print(f'L = {i}, layer = {layer}')\n",
    "\n",
    "#n = np.random.uniform(0,1,(1,32,32,3))\n",
    "\n",
    "maps = keras.Model(dis.input, dis.layers[7].output)\n",
    "# map = maps(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_weights(model,clip_value=0.1):\n",
    "    \n",
    "    for layer in model.trainable_variables:\n",
    "        layer.assign(tf.clip_by_value(layer, -clip_value, clip_value))\n",
    "\n",
    "# def gradient_penalty(discriminator, real_samples, fake_samples):\n",
    "#     alpha = tf.random.uniform((real_samples.shape[0],), 0, 1)\n",
    "#     interpolated_samples = alpha[0] * real_samples + (1 - alpha[0]) * fake_samples\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         tape.watch(interpolated_samples)\n",
    "#         predictions = discriminator(interpolated_samples)\n",
    "#     gradients = tape.gradient(predictions, interpolated_samples)\n",
    "#     gradients_norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=1))\n",
    "#     penalty = tf.reduce_mean((gradients_norm - 1) ** 2)\n",
    "#     return penalty\n",
    "\n",
    "# def wasser_dist(y_true,y_pred):\n",
    "#     return tf.reduce_mean(y_true * y_pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step():\n",
    "    gen_loss,dis_loss = 0.,0.\n",
    "    gen_loss_iter,dis_loss_iter = 0.,0.\n",
    "    for batch in data:\n",
    "        \n",
    "        noise = tf.random.normal((batch_size,128))\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape:\n",
    "            fake_imgs = gen(noise,training=True)\n",
    "            true_labels = dis(batch,training=True)\n",
    "            fake_labels = dis(fake_imgs,training=True)\n",
    "            #true_map = maps(batch,training=True)\n",
    "            #fake_map = maps(fake_imgs, training=True)\n",
    "\n",
    "            \n",
    "            gen_loss_iter = bce(tf.ones_like(fake_labels),fake_labels) #- (1/2)*tf.reduce_mean(tf.math.reduce_std(fake_imgs,axis=0))\n",
    "            dis_loss_iter = bce(tf.ones_like(true_labels),true_labels) + bce(tf.zeros_like(fake_labels),fake_labels)\n",
    "            # dis_loss_iter = tf.reduce_mean(fake_labels) - tf.reduce_mean(true_labels)\n",
    "            # gen_loss_iter = -tf.reduce_mean(fake_labels) + MSE(true_map,fake_map)\n",
    "        \n",
    "        gen_gras = gen_tape.gradient(gen_loss_iter,gen.trainable_variables)\n",
    "        gen_opt.apply_gradients(zip(gen_gras,gen.trainable_variables))\n",
    "\n",
    "        dis_grads = dis_tape.gradient(dis_loss_iter,dis.trainable_variables)\n",
    "        dis_opt.apply_gradients(zip(dis_grads,dis.trainable_variables))\n",
    "\n",
    "        gen_loss += gen_loss_iter\n",
    "        dis_loss += dis_loss_iter\n",
    "        gen_loss_iter,dis_loss_iter = 0.,0.\n",
    "\n",
    "    return gen_loss/tf.cast(len(data),tf.float32),dis_loss/tf.cast(len(data),tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742827116.637846  291117 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep = 0 | Loss_gen = 1.0539; Loss_dis = 112.2770\n",
      "Ep = 10 | Loss_gen = 2.3773; Loss_dis = 4.0580\n",
      "Ep = 20 | Loss_gen = 1.7248; Loss_dis = 3.3013\n",
      "Ep = 30 | Loss_gen = 1.3907; Loss_dis = 2.6103\n",
      "Ep = 40 | Loss_gen = 1.1116; Loss_dis = 2.0926\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5000\n",
    "EPOCH_SAMPLE = 10\n",
    "\n",
    "loss_dis, loss_gen = 0.,0.\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "\n",
    "    # Histórico de Loss\n",
    "    \n",
    "    loss_gen, loss_dis = train_step()\n",
    "    #loss_gen, loss_dis = loss_gen.numpy(), loss_dis.numpy()\n",
    "    clip_weights(dis,0.1)\n",
    "    complete_hist['loss_gen'].append(loss_gen)\n",
    "    complete_hist['loss_dis'].append(loss_dis)\n",
    "    \n",
    "    # Iteração das épocas\n",
    "    if i % EPOCH_SAMPLE == 0:\n",
    "        # Print Loss\n",
    "        print(f'Ep = {i} | Loss_gen = {loss_gen:.4f}; Loss_dis = {loss_dis:.4f}')\n",
    "        # Salvar uma amostra das imagens\n",
    "        img_fake = gen(noise_out)\n",
    "        fig, ax = plt.subplots(n,n,figsize=(1,1))\n",
    "        ax = ax.ravel()\n",
    "        for ii in range(n**2):\n",
    "            ax[ii].imshow(np.uint8(img_fake[ii]*127.5+127.5))\n",
    "            ax[ii].set_axis_off()\n",
    "        plt.savefig(f'imgs/fig{i}.png',dpi=1000)\n",
    "        plt.close()\n",
    "\n",
    "    plt.semilogy(np.array(complete_hist['loss_gen']),label=f'GEN = {loss_gen:.4f}')\n",
    "    plt.semilogy(np.array(complete_hist['loss_dis']),label=f'DIS = {loss_dis:.4f}')\n",
    "    plt.legend()\n",
    "    plt.grid(True,'minor')\n",
    "    plt.savefig('loss.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "print('==================== COMPLETE ====================')\n",
    "\n",
    "# plt.Figure()\n",
    "# plt.plot(loss_list[:,0],label='Discriminator')\n",
    "# plt.plot(loss_list[:,1],label='GAN')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.save('generator_cars.keras')\n",
    "dis.save('discriminator_cars.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "\n",
    "noise_out = tf.random.normal((1000,1024))\n",
    "\n",
    "img_fake = gen(noise_out)\n",
    "out_true = dis(x_train[0:1000])\n",
    "out_fake = dis(gen(tf.random.uniform((1000,1024))))\n",
    "\n",
    "print(f'Média True = {tf.reduce_mean(out_true):.4f} \\nMédia False = {tf.reduce_mean(out_fake):.4f}')\n",
    "\n",
    "plt.Figure()\n",
    "plt.semilogy(np.array(complete_hist['loss_gen']),label='GEN')\n",
    "plt.semilogy(np.array(complete_hist['loss_dis']),label='DIS')\n",
    "plt.legend()\n",
    "plt.grid(True,'minor')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(n,n,figsize=(10,10))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i in range(n**2):\n",
    "    ax[i].imshow(img_fake[i])\n",
    "    ax[i].set_axis_off()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
